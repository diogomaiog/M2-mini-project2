{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferential statistics\n",
    "## Part I - Data Cleaning\n",
    "\n",
    "Your family is very passionate about basketball. You always have discussions over players, games, statistics and whatnot. As you can imagine those discussions never reach a conclusion since everyone is simply sharing their opinion with no statistics to back them up!\n",
    "\n",
    "![](../images/basket.jpg)\n",
    "\n",
    "Since you are attending a data analysis bootcamp you'd like to take advantage of your newfound knowledge to finally put an end to your family's discussions. \n",
    "\n",
    "Luckily we have found a dataset containing data related to the players of the WNBA for the 2016-2017 season that we can use. \n",
    "\n",
    "Let's start with cleaning the data and then we'll continue with a general exploratory analysis and some inferential statistics.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "The dataset we will be using contains the statistics from the WNBA players for the 2016-2017 season. You will be able to find more information on the dataset in the [codebook](../data/codebook.md) uploaded to the repository.\n",
    "\n",
    "### Libraries\n",
    "\n",
    "First we'll import the necessary libraries first and increase the maximum number of displayed columns so you will be able to see all the dataset in the same window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n",
    "\n",
    "Load the dataset into a df called `wnba` and take an initial look at it using the `head()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#your code here\n",
    "wnba = pd.read_csv('../data/wnba.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check NaN values\n",
    "As you know, one of our first steps is to check if there are any NaN values in the dataset to find any issues. Look for the columns that cointain NaN values and count how many rows there are with that value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name            0\n",
      "Team            0\n",
      "Pos             0\n",
      "Height          0\n",
      "Weight          1\n",
      "BMI             1\n",
      "Birth_Place     0\n",
      "Birthdate       0\n",
      "Age             0\n",
      "College         0\n",
      "Experience      0\n",
      "Games Played    0\n",
      "MIN             0\n",
      "FGM             0\n",
      "FGA             0\n",
      "FG%             0\n",
      "3PM             0\n",
      "3PA             0\n",
      "3P%             0\n",
      "FTM             0\n",
      "FTA             0\n",
      "FT%             0\n",
      "OREB            0\n",
      "DREB            0\n",
      "REB             0\n",
      "AST             0\n",
      "STL             0\n",
      "BLK             0\n",
      "TO              0\n",
      "PTS             0\n",
      "DD2             0\n",
      "TD3             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "#wnba.isnull().sum().sum()\n",
    "count_nan_in_df = wnba.isnull().sum()\n",
    "print (count_nan_in_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are only two NaNs in the whole dataset, one in the Weight column and one in the BMI one. Let's look at the actual rows that contain the NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Name Team Pos  Height  Weight  BMI Birth_Place     Birthdate  Age  \\\n",
      "91  Makayla Epps  CHI   G     178     NaN  NaN          US  June 6, 1995   22   \n",
      "\n",
      "     College Experience  Games Played  MIN  FGM  FGA   FG%  3PM  3PA  3P%  \\\n",
      "91  Kentucky          R            14   52    2   14  14.3    0    5  0.0   \n",
      "\n",
      "    FTM  FTA   FT%  OREB  DREB  REB  AST  STL  BLK  TO  PTS  DD2  TD3  \n",
      "91    2    5  40.0     2     0    2    4    1    0   4    6    0    0  \n",
      "            Name Team Pos  Height  Weight  BMI Birth_Place     Birthdate  Age  \\\n",
      "91  Makayla Epps  CHI   G     178     NaN  NaN          US  June 6, 1995   22   \n",
      "\n",
      "     College Experience  Games Played  MIN  FGM  FGA   FG%  3PM  3PA  3P%  \\\n",
      "91  Kentucky          R            14   52    2   14  14.3    0    5  0.0   \n",
      "\n",
      "    FTM  FTA   FT%  OREB  DREB  REB  AST  STL  BLK  TO  PTS  DD2  TD3  \n",
      "91    2    5  40.0     2     0    2    4    1    0   4    6    0    0  \n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "print(wnba[wnba['Weight'].isnull()])\n",
    "print(wnba[wnba['BMI'].isnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there is only a single row that has NaN values in it, which is good! Just in case, let's check how much removing a single row may influence our dataset by calculating the percentage of values we will be removing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of values removed is 0.66 %.\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# counting only the non - null values of the row with null values \n",
    "\n",
    "perc = (wnba[wnba['Weight'].isnull()].size - 2) / wnba.size * 100\n",
    "print(f'The percentage of values removed is {round(perc,2)} %.')\n",
    "\n",
    "# sanity check\n",
    "#1 / wnba['Weight'].size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very important to be as careful as possible when dealing with NaN values and only drop data when it is strictly necessary. This decision can also be influenced by the nature of our analysis. If, for example, our analysis will not require the Weight and BMI of the players at all we can simply keep the row, given that the NaN values are only present in the Weight and BMI column.\n",
    "\n",
    "In this specific example, let's say our decision is to drop it. Write some code to drop the NaN values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4576\n",
      "4544\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "print(wnba.size)\n",
    "wnba.drop(index = wnba.index[wnba['Weight'].isnull()], inplace = True)\n",
    "print(wnba.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do you think it is a good decision? Think about a case in which you wouldn't want to drop the value.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here\n",
    "# If the dataset was small, or if the sub-set where this row would fit is small.\n",
    "# I think in this case it is probably a good decision because the amount of data lost is so small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's make an overview of the dataset\n",
    "First, check the data types of our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name             object\n",
       "Team             object\n",
       "Pos              object\n",
       "Height            int64\n",
       "Weight          float64\n",
       "BMI             float64\n",
       "Birth_Place      object\n",
       "Birthdate        object\n",
       "Age               int64\n",
       "College          object\n",
       "Experience       object\n",
       "Games Played      int64\n",
       "MIN               int64\n",
       "FGM               int64\n",
       "FGA               int64\n",
       "FG%             float64\n",
       "3PM               int64\n",
       "3PA               int64\n",
       "3P%             float64\n",
       "FTM               int64\n",
       "FTA               int64\n",
       "FT%             float64\n",
       "OREB              int64\n",
       "DREB              int64\n",
       "REB               int64\n",
       "AST               int64\n",
       "STL               int64\n",
       "BLK               int64\n",
       "TO                int64\n",
       "PTS               int64\n",
       "DD2               int64\n",
       "TD3               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code here\n",
    "wnba.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like most of the data types are correct. Birthdate column could be casted to a `datetime` type, however, we won't use it in our analysis so for simplicity, let's leave it as an `object`. Weight column could also be casted to an `int64` type as all numbers are integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's change the type of Weight column for practice.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name             object\n",
       "Team             object\n",
       "Pos              object\n",
       "Height            int64\n",
       "Weight            int32\n",
       "BMI             float64\n",
       "Birth_Place      object\n",
       "Birthdate        object\n",
       "Age               int64\n",
       "College          object\n",
       "Experience       object\n",
       "Games Played      int64\n",
       "MIN               int64\n",
       "FGM               int64\n",
       "FGA               int64\n",
       "FG%             float64\n",
       "3PM               int64\n",
       "3PA               int64\n",
       "3P%             float64\n",
       "FTM               int64\n",
       "FTA               int64\n",
       "FT%             float64\n",
       "OREB              int64\n",
       "DREB              int64\n",
       "REB               int64\n",
       "AST               int64\n",
       "STL               int64\n",
       "BLK               int64\n",
       "TO                int64\n",
       "PTS               int64\n",
       "DD2               int64\n",
       "TD3               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code here\n",
    "wnba['Weight'] = wnba['Weight'].astype('int32')\n",
    "wnba.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After checking the data types, let's check for outliers using the describe() method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Age</th>\n",
       "      <th>Games Played</th>\n",
       "      <th>MIN</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3PM</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TO</th>\n",
       "      <th>PTS</th>\n",
       "      <th>DD2</th>\n",
       "      <th>TD3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>184.612676</td>\n",
       "      <td>78.978873</td>\n",
       "      <td>23.091214</td>\n",
       "      <td>27.112676</td>\n",
       "      <td>24.429577</td>\n",
       "      <td>500.105634</td>\n",
       "      <td>74.401408</td>\n",
       "      <td>168.704225</td>\n",
       "      <td>43.102817</td>\n",
       "      <td>14.830986</td>\n",
       "      <td>43.697183</td>\n",
       "      <td>24.978169</td>\n",
       "      <td>39.535211</td>\n",
       "      <td>49.422535</td>\n",
       "      <td>75.828873</td>\n",
       "      <td>22.063380</td>\n",
       "      <td>61.591549</td>\n",
       "      <td>83.654930</td>\n",
       "      <td>44.514085</td>\n",
       "      <td>17.725352</td>\n",
       "      <td>9.781690</td>\n",
       "      <td>32.288732</td>\n",
       "      <td>203.169014</td>\n",
       "      <td>1.140845</td>\n",
       "      <td>0.007042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.698128</td>\n",
       "      <td>10.996110</td>\n",
       "      <td>2.073691</td>\n",
       "      <td>3.667180</td>\n",
       "      <td>7.075477</td>\n",
       "      <td>289.373393</td>\n",
       "      <td>55.980754</td>\n",
       "      <td>117.165809</td>\n",
       "      <td>9.855199</td>\n",
       "      <td>17.372829</td>\n",
       "      <td>46.155302</td>\n",
       "      <td>18.459075</td>\n",
       "      <td>36.743053</td>\n",
       "      <td>44.244697</td>\n",
       "      <td>18.536151</td>\n",
       "      <td>21.519648</td>\n",
       "      <td>49.669854</td>\n",
       "      <td>68.200585</td>\n",
       "      <td>41.490790</td>\n",
       "      <td>13.413312</td>\n",
       "      <td>12.537669</td>\n",
       "      <td>21.447141</td>\n",
       "      <td>153.032559</td>\n",
       "      <td>2.909002</td>\n",
       "      <td>0.083918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>165.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>18.390675</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>175.750000</td>\n",
       "      <td>71.500000</td>\n",
       "      <td>21.785876</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>242.250000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>37.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>71.575000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>34.250000</td>\n",
       "      <td>11.250000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>77.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>185.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>22.873314</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>152.500000</td>\n",
       "      <td>42.050000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>30.550000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>191.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>24.180715</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>752.500000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>244.750000</td>\n",
       "      <td>48.625000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>65.500000</td>\n",
       "      <td>36.175000</td>\n",
       "      <td>53.250000</td>\n",
       "      <td>66.500000</td>\n",
       "      <td>85.925000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>116.500000</td>\n",
       "      <td>66.750000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>277.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>206.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>31.555880</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1018.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>509.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Height      Weight         BMI         Age  Games Played  \\\n",
       "count  142.000000  142.000000  142.000000  142.000000    142.000000   \n",
       "mean   184.612676   78.978873   23.091214   27.112676     24.429577   \n",
       "std      8.698128   10.996110    2.073691    3.667180      7.075477   \n",
       "min    165.000000   55.000000   18.390675   21.000000      2.000000   \n",
       "25%    175.750000   71.500000   21.785876   24.000000     22.000000   \n",
       "50%    185.000000   79.000000   22.873314   27.000000     27.500000   \n",
       "75%    191.000000   86.000000   24.180715   30.000000     29.000000   \n",
       "max    206.000000  113.000000   31.555880   36.000000     32.000000   \n",
       "\n",
       "               MIN         FGM         FGA         FG%         3PM  \\\n",
       "count   142.000000  142.000000  142.000000  142.000000  142.000000   \n",
       "mean    500.105634   74.401408  168.704225   43.102817   14.830986   \n",
       "std     289.373393   55.980754  117.165809    9.855199   17.372829   \n",
       "min      12.000000    1.000000    3.000000   16.700000    0.000000   \n",
       "25%     242.250000   27.000000   69.000000   37.125000    0.000000   \n",
       "50%     506.000000   69.000000  152.500000   42.050000   10.500000   \n",
       "75%     752.500000  105.000000  244.750000   48.625000   22.000000   \n",
       "max    1018.000000  227.000000  509.000000  100.000000   88.000000   \n",
       "\n",
       "              3PA         3P%         FTM         FTA         FT%        OREB  \\\n",
       "count  142.000000  142.000000  142.000000  142.000000  142.000000  142.000000   \n",
       "mean    43.697183   24.978169   39.535211   49.422535   75.828873   22.063380   \n",
       "std     46.155302   18.459075   36.743053   44.244697   18.536151   21.519648   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      3.000000    0.000000   13.000000   17.250000   71.575000    7.000000   \n",
       "50%     32.000000   30.550000   29.000000   35.500000   80.000000   13.000000   \n",
       "75%     65.500000   36.175000   53.250000   66.500000   85.925000   31.000000   \n",
       "max    225.000000  100.000000  168.000000  186.000000  100.000000  113.000000   \n",
       "\n",
       "             DREB         REB         AST         STL         BLK          TO  \\\n",
       "count  142.000000  142.000000  142.000000  142.000000  142.000000  142.000000   \n",
       "mean    61.591549   83.654930   44.514085   17.725352    9.781690   32.288732   \n",
       "std     49.669854   68.200585   41.490790   13.413312   12.537669   21.447141   \n",
       "min      2.000000    2.000000    0.000000    0.000000    0.000000    2.000000   \n",
       "25%     26.000000   34.250000   11.250000    7.000000    2.000000   14.000000   \n",
       "50%     50.000000   62.500000   34.000000   15.000000    5.000000   28.000000   \n",
       "75%     84.000000  116.500000   66.750000   27.500000   12.000000   48.000000   \n",
       "max    226.000000  334.000000  206.000000   63.000000   64.000000   87.000000   \n",
       "\n",
       "              PTS         DD2         TD3  \n",
       "count  142.000000  142.000000  142.000000  \n",
       "mean   203.169014    1.140845    0.007042  \n",
       "std    153.032559    2.909002    0.083918  \n",
       "min      2.000000    0.000000    0.000000  \n",
       "25%     77.250000    0.000000    0.000000  \n",
       "50%    181.000000    0.000000    0.000000  \n",
       "75%    277.750000    1.000000    0.000000  \n",
       "max    584.000000   17.000000    1.000000  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code here\n",
    "wnba.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment on your result. What do you see?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Height': 0, 'Weight': 3, 'BMI': 5, 'Age': 0, 'Games Played': 12, 'MIN': 0, 'FGM': 2, 'FGA': 1, 'FG%': 5, '3PM': 5, '3PA': 3, '3P%': 2, 'FTM': 10, 'FTA': 9, 'FT%': 9, 'OREB': 5, 'DREB': 8, 'REB': 7, 'AST': 4, 'STL': 1, 'BLK': 12, 'TO': 0, 'PTS': 2, 'DD2': 18, 'TD3': 142}\n"
     ]
    }
   ],
   "source": [
    "#your answer here\n",
    "\n",
    "# This is a lot of columns, let's hunt for outliers. \n",
    "# Let's consider and outlier any value that is at least 1.5 interquartile ranges below the first quartile ou above \n",
    "# the third quartile.\n",
    "\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "outliers = {}\n",
    "for (columnName, columnData) in wnba.iteritems():\n",
    "    if is_numeric_dtype(wnba[columnName]):\n",
    "        Q1 = wnba[columnName].quantile(.25)\n",
    "        Q2 = wnba[columnName].quantile(.75)\n",
    "        IQR = Q2 - Q1\n",
    "        lower_b = Q1 - 1.5 * IQR\n",
    "        upper_b = Q2 + 1.5 * IQR \n",
    "        count = 0\n",
    "        for i in columnData:\n",
    "            if i >= upper_b or i <= lower_b:\n",
    "                count += 1\n",
    "        outliers[columnName] = count\n",
    "print(outliers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "According to our rule of thumb, we find a few outliers in most columns,\n",
    "the weirdest data is in column 'TD3', that I guess has very few values different from 0, and our rule ends ups flaging all\n",
    "entries as outliers.\n",
    "It would be interesting to check out the players that are outliers in some attributes (like 'FTM', 'FTA', 'FT%', 'DREB', \n",
    "'REB'), they may be really good or really bad players. \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we can save the cleaned data to a new .csv file called `wnba_clean.csv` in the data folder.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "wnba.to_csv('../data/wnba_clean.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
